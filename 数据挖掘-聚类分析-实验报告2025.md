# 华东师范大学软件工程学院实验报告

## 课程信息
- **课程名称**：数据挖掘
- **学号**：10235101415
- **姓名**：任宇航
- **作业名称**：聚类分析
- **日期**：2025-11
- **教师**：王丽苹

---

## 一、作业要求

本次作业要求每位同学根据所学的聚类算法如K-means、层次聚类、密度聚类、谱聚类算法等完成对数据集的聚类分析实验，具体要求如下:

- 至少选择4种聚类算法进行实验，除了课堂的内容之外，鼓励自己引入新的聚类算法进行实验；
- 要求自己根据所学知识设计聚类算法的评估指标，统计在不同数据集下算法的指标表现情况；
- 要求设计可视化的方法，直观分析不同算法的表现情况；
- 要求能够统计算法的效率，并进行对比；

---

## 二、数据集

本次算法实验推荐的数据集有4个，具体如下：

1. **二维空间的点集**
   - 包括1000个二维空间的点
   - 文件名：`data-8-2-1000.txt`

2. **Kaggle的股票数据集**
   - 包括标准普尔500指数的数据，有490家企业的470天的股票价格信息
   - 字段有：Date(日期)，ABT、ABBV、ACN等为相应公司的股价
   - 文件名：`SP500array.csv`

3. **Kaggle的消费者数据集**
   - 包括200个匿名消费者信息
   - 字段有：CustomerID(用户编号),Genere(性别)，Age(年龄)，Annual Income(年收入)，Spending Score（消费得分）等
   - 文件名：`Mall_Customers.csv`

4. **Kaggle的信用卡数据集**
   - 包括8950个用户的信用卡数据
   - 字段有：CUST_ID(用户编号),BALANCE(余额)，BALANCE_FREQUENCY(余额频率)，PRC_FULL_PAYMENT(全款占比)，TENURE(信用卡期限)等18个字段
   - 文件名：`CC_GENERAL.csv`

---

## 三、本地实验环境

- **CPU**：AMD锐龙7735H
- **内存**：16.0 GB(8*2 4800MHZ)
- **操作系统**：Windows 11 专业版
- **编程语言**：Python
- **编译器**：Python3.12.2

---

## 四、实验记录和结果

### 1. 1000点数据集

使用了7种方法，包括两种借助dnn的方法和kmeans,optics,dbscan,层次聚类，谱聚类

#### DNNv1方法
使用一个dnn网络输出每个点位于某一簇的概率，根据每簇点位置按概率的加权平均计算出聚类中心，损失函数组合了簇内间距和簇间间距。

**实验结果**：
- 效果一般，训练成本高，损失不收敛
- 可用于预测簇中心，但预测点属于某个簇的效果较差
- 模型泛化性差

#### DNNv2方法
使用dnn直接预测簇中心，将损失函数作为评价指标，利用梯度下降最小化这个指标。

**实验结果**：
- 模型没有泛化性
- 受初始分布影响大，容易进入局部最优
- 理论上所有可以传递梯度的聚类评价指标都可以做损失函数

#### 评估指标对比

**DNNv1评估指标**：
```
dnnv1_6聚类评估指标:
轮廓系数: 0.4462
Calinski-Harabasz指数: 2427.9624
Davies-Bouldin指数: 0.8901

dnnv1_5聚类评估指标:
轮廓系数: 0.5575
Calinski-Harabasz指数: 3197.2022
Davies-Bouldin指数: 0.6113

dnnv1_4聚类评估指标:
轮廓系数: 0.5617
Calinski-Harabasz指数: 3311.2669
Davies-Bouldin指数: 0.6107

dnnv1_3聚类评估指标:
轮廓系数: 0.5429
Calinski-Harabasz指数: 2876.8284
Davies-Bouldin指数: 0.5063
```

**DNNv2评估指标**：
```
dnnv2_6聚类评估指标:
轮廓系数: 0.6283
Calinski-Harabasz指数: 8490.8633
Davies-Bouldin指数: 0.6765

dnnv2_5聚类评估指标:
轮廓系数: 0.7157
Calinski-Harabasz指数: 9878.3914
Davies-Bouldin指数: 0.3995

dnnv2_4聚类评估指标:
轮廓系数: 0.6623
Calinski-Harabasz指数: 6091.6932
Davies-Bouldin指数: 0.4911

dnnv2_3聚类评估指标:
轮廓系数: 0.6311
Calinski-Harabasz指数: 3885.8931
Davies-Bouldin指数: 0.4399
```

**传统算法评估指标**：
```
kmeans_6聚类评估指标:
轮廓系数: 0.6338
Calinski-Harabasz指数: 8462.3818
Davies-Bouldin指数: 0.6700

kmeans_5聚类评估指标:
轮廓系数: 0.7157
Calinski-Harabasz指数: 9878.3863
Davies-Bouldin指数: 0.3995

dbscan_0.7_8聚类评估指标:
轮廓系数: 0.600
Calinski-Harabasz指数: 4575.524
Davies-Bouldin指数: 0.468

OPTICS_20_0.05_0.05聚类评估指标:
轮廓系数: 0.668
Calinski-Harabasz指数: 7886.176
Davies-Bouldin指数: 2.009
```

### 2. Customers数据集

#### 评估指标对比

**K-means算法**：
```
kmeans3聚类评估指标:
轮廓系数: 0.4676
Calinski-Harabasz指数: 151.5570
Davies-Bouldin指数: 0.7153

kmeans4聚类评估指标:
轮廓系数: 0.4932
Calinski-Harabasz指数: 174.0644
Davies-Bouldin指数: 0.7104
```

**密度聚类算法**：
```
OPTICS_5_0.1_0.1聚类评估指标:
轮廓系数: 0.157
Calinski-Harabasz指数: 40.858
Davies-Bouldin指数: 5.472

DBSCAN_10_7算法评估指标:
轮廓系数: 0.421
Calinski-Harabasz指数: 78.446
Davies-Bouldin指数: 1.424
```

### 3. GENERAL数据集

这个数据集降维后分布比较特殊，只选取了四个算法进行测试

**评估指标**：
```
OPTICS_20_0.02_0.05聚类评估指标:
轮廓系数: 0.638
Calinski-Harabasz指数: 2586.253
Davies-Bouldin指数: 1.037

DBSCAN_0.7_8算法评估指标:
轮廓系数: 0.683
Calinski-Harabasz指数: 871.417
Davies-Bouldin指数: 0.977

K-means_3算法评估指标:
轮廓系数: 0.443
Calinski-Harabasz指数: 5137.121
Davies-Bouldin指数: 0.826

谱聚类评估指标:
轮廓系数: 0.879
Calinski-Harabasz指数: 466.136
Davies-Bouldin指数: 0.212
```

### 4. SP500股票数据集

这个数据集的每个数据是一个有时序关系的序列，所以将它看作一个高维空间上的点进行聚类是没有实际意义的。可以将每个数据进行标准化，并定义一个与序列相关系数有关的值作为距离，进行聚类。

**距离定义代码**：
```python
# 计算相关系数矩阵
print("正在计算相关系数矩阵...")
correlation_matrix = np.corrcoef(data)

# 转换矩阵元素：1/(相关系数的绝对值+0.0001) - (1/1.0001)
print("正在转换矩阵元素...")
transformed_matrix = 1 / (np.abs(correlation_matrix) + 0.0001) - (1 / 1.0001)
```

**评估指标**：
```
层次1.4聚类评估指标:
轮廓系数: -0.557

层次1.3聚类评估指标:
轮廓系数: -0.498

谱聚类1评估指标:
轮廓系数: -0.515

DBSCAN1算法评估指标:
轮廓系数: -0.184
```

---

## 五、结论

通过本次聚类分析实验，我深刻体会到理论与实践相结合的重要性。在完成四个不同特性数据集的聚类分析过程中，我获得了许多宝贵的经验和见解。

### 主要收获

1. **算法选择的重要性**
   - 没有"万能"的聚类算法
   - 选择聚类算法必须充分考虑数据的分布特性、维度、噪声水平等要素

2. **参数调优的经验**
   - DBSCAN和OPTICS等密度聚类算法对参数极其敏感
   - 学会了如何根据数据特性调整eps和min_samples参数
   - 学会了利用k-距离图等工具辅助参数选择

3. **深度学习方法探索**
   - 尝试用深度学习解决聚类问题是一次大胆的创新
   - DNN方法训练成本高、收敛困难的问题提醒创新需要建立在充分的理论分析基础上

4. **距离度量的重要性**
   - 在处理股票数据时创新性地设计了基于相关系数的距离度量
   - 认识到合适的距离度量对聚类效果的决定性影响

5. **评估指标的综合使用**
   - 单一指标往往有局限性，需要综合多个指标才能全面评估聚类质量
   - 不同指标可能给出矛盾的结论，需要结合业务理解和可视化结果做出判断

### 工程能力提升
- 从数据预处理、算法实现到结果可视化的完整实现大大提升了工程能力
- 在处理大规模数据时的效率优化、内存管理等方面获得宝贵经验

### 问题解决能力
- 在实验过程中遇到了算法不收敛、内存溢出、可视化效果不佳等问题
- 通过查阅文档、调试代码、寻求替代方案，问题解决能力得到显著提升

### 不足与改进方向
- 参数选择还较多依赖经验和试错，未来可以探索更系统的参数优化方法
- 对某些算法（如谱聚类）的数学原理理解还不够深入，需要进一步加强理论学习

---

## 六、大模型的使用说明

本次实验主要借助大模型查询各种包的函数及其使用说明文档，还有部分可视化代码的生成。

---

## 七、代码附录

见附件。对于不同数据代码可能不同，可见注释掉的部分。

---
*注：本报告由Word文档自动转换为Markdown格式生成*
